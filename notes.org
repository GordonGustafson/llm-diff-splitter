https://unix.stackexchange.com/questions/480443/how-shall-i-understand-the-unified-format-of-diff-output

* Eval results differing base on batch sizes
Seems like this comes from using float16/bfloat16?
https://github.com/huggingface/transformers/issues/23017#issuecomment-1649630232
https://discuss.huggingface.co/t/results-of-model-generate-are-different-for-different-batch-sizes-of-the-decode-only-model/34878/3
https://discuss.huggingface.co/t/ask-for-help-output-inconsistency-when-using-llm-batch-inference-compared-to-single-input/146303/4

* Evaluation Approaches
** diffs should combine into combined diff
combinediff from patchutils can combine diffs
** initial state should match initial, middle should match middle, and final should match final
use some sort of string comparison to compare initial, middle, and final states?

there's 7 states:
ground truth start, middle, and end
model output start of first diff, end of first diff, start of second diff, end of second diff

loss = dist(gt_start, d1_start) + dist(gt_mid, d1_end) + dist(gt_mid, d2_start) + dist(gt_end, d2_end)
reward = -loss

* patch applying libraries
** diff-match-patch
Doesn't support unified diff format, see https://github.com/google/diff-match-patch/wiki/Unidiff
** patch
** diffpatch


* good things the model does right now
generate fake commit hash that's consistent between the before and after diffs

* bad things the model does right now
duplicate divider token
duplicate diffs
forget the diff header
diff with no + or - lines

** adding and removing identical lines:
-    def test_searchsorted_wrong_dtype(self):
+    def test_searchsorted_wrong_dtype(self):

-Using the scheme ``socks5`` causes the DNS resolution to happen on the client, rather than on the proxy server. This is in line with curl, which uses the scheme to decide whether to do the DNS resolution on the client or proxy. If you want to resolve the domains on the proxy server, use ``socks5h`` as the scheme.
+Using the scheme ``socks5`` causes the DNS resolution to happen on the client, rather than on the proxy server. This is in line with curl, which uses the scheme to decide whether to do the DNS resolution on the client or proxy. If you want to resolve the domains on the proxy server, use ``socks5h`` as the scheme.



* 
https://huggingface.co/blog/the_n_implementation_details_of_rlhf_with_ppo

* inference output
input str:
diff --git a/data/convert_patches_to_parquet.py b/data/convert_patches_to_parquet.py
index 19af536..7f3068c 100644
--- a/data/convert_patches_to_parquet.py
+++ b/data/convert_patches_to_parquet.py
@@ -10,7 +10,7 @@ SMALL_COMBINED_DIFF_THRESHOLD = 1000
 
 directory_of_script = pathlib.Path(__file__).parent.resolve()
 
-directory_of_tar_files = directory_of_script / "patches"
+directory_of_tar_files = directory_of_script / "patches.backup"
 all_diffs_output_path = directory_of_script / "all_diffs.parquet"
 small_diffs_output_path = directory_of_script / f"combined-diffs-less-than-{SMALL_COMBINED_DIFF_THRESHOLD}-chars.parquet"
 
diff --git a/train.py b/train.py
index e581f23..ccabb69 100644
--- a/train.py
+++ b/train.py
@@ -13,7 +13,7 @@ from data.dataset import load_huggingface_dataset
 
 
 MODEL_NAME = "meta-llama/Llama-3.2-1B"
-MAX_TOKEN_LENGTH = 2048
+MAX_TOKEN_LENGTH = 1536
 PARQUET_DATASET_PATH = Path("data/combined-diffs-less-than-1000-chars.parquet")
 
 
 ################################################################################
 
-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
################################################################################
diff --git a/data/convert_patches_to_parquet.py b/data/convert_patches_to_parquet.py
index 19af536..7f3068c 100644
--- a/data/convert_patches_to_parquet.py
+++ b/data/convert_patches_to_parquet.py
@@ -10,7 +10,7 @@ SMALL_COMBINED_DIFF_THRESHOLD = 1000
 
 directory_of_script = pathlib.Path(__file__).parent.resolve()
 
-directory_of_tar_files = directory_of_script / "patches"
+directory_of_tar_files = directory_of_script / "patches.backup"
 all_diffs_output_path = directory_of_script / "all_diffs.parquet"
 small_diffs_output_path = directory_of_script / f"combined-diffs-less-than-{SMALL_COMBINED_DIFF_THRESHOLD}-chars.parquet"
 
diff --git a/train.py b/train.py
index e581f23..ccabb69 100644
--- a/train.py
+++ b/train.py
@@ -13,7 +13,7 @@ from data.dataset import load_huggingface_dataset
 
 
 MODEL_NAME = "meta-llama/Llama-3.2-1B"
-MAX_TOKEN_LENGTH = 2048
+MAX_TOKEN_LENGTH = 1536
 PARQUET_DATASET_PATH = Path("data/combined-diffs-less-than-1000-chars.parquet")
 
 
 ################################################################################
 ################################################################################

-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
################################################################################
################################################################################
diff --git a/train.py b/train.py
index e581f23..ccabb69 100644
--- a/train.py
+++ b/train.py
@@ -13,7 +13,7 @@ from data.dataset import load_huggingface_dataset
 
 
 MODEL_NAME = "meta-llama/Llama-3.2-1B"
-MAX_TOKEN_LENGTH = 2048
+MAX_TOKEN_LENGTH = 1536
 PARQUET_DATASET_PATH = Path("data/combined-diffs-less-than-1000-chars.parquet")
 
 
 ################################################################################
 ################################################################################
################################################################################
diff --git a/data/convert_patches_to_parquet.py b/data/convert_patches_to_parquet.py
index 19af536..7f3068c 100644
--- a/data/convert_patches_to_parquet.py
+++ b/data/convert_patches_to_parquet.py
@@ -10,7 +10,7 @@ SMALL_COMBINED_DIFF_THRESHOLD = 1000
 
 directory_of_script = pathlib.Path(__file__).parent.resolve()
 
-directory_of_tar_files = directory_of_script / "patches"
+directory_of_tar_files = directory_of_script / "patches.backup"
 all_diffs_output_path = directory_of_script / "all_diffs.parquet"
 small_diffs_output_path = directory_of_script / f"combined-diffs-less-than-{SMALL_COMBINED_DIFF_THRESHOLD}-chars.parquet"
 
diff --git a/train.py b/train.py
index ccabb69..e581f23 100644
--- a/train.py
+++ b/train.py
@@ -13,7 +13,7 @@ from data.dataset import load_huggingface_dataset
 
 
 MODEL_NAME = "meta-llama/Llama-3.2-1B"
-MAX_TOKEN_LENGTH = 1536
+MAX_TOKEN_LENGTH = 2048
 PARQUET_DATASET_PATH = Path("data/combined-diffs-less-than-1000-chars.parquet")
 
 
 
-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
################################################################################
diff --git a/train.py b/train.py
index e581f23..ccabb69 100644
--- a/train.py
+++ b/train.py
@@ -13,7 +13,7 @@ from data.dataset import load_huggingface_dataset
 
 
 MODEL_NAME = "meta-llama/Llama-3.2-1B"
-MAX_TOKEN_LENGTH = 2048
+MAX_TOKEN_LENGTH = 1536
 PARQUET_DATASET_PATH = Path("data/combined-diffs-less-than-1000-chars.parquet")
 
 
 ################################################################################
 ################################################################################
 
 directory_of_script = pathlib.Path(__file__).parent.resolve()
 
-directory_of_tar_files = directory_of_script / "patches"
+directory_of_tar_files = directory_of_script / "patches.backup"
 all_diffs_output_path = directory_of_script / "all_diffs.parquet"
 small_diffs_output_path = directory_of_script / f"combined-diffs-less-than-{SMALL_COMBINED_DIFF_THRESHOLD}-chars.parquet"
 
################################################################################
diff --git a/data/convert_patches_to_parquet.py b/data/convert_patches_to_parquet.py
index 19af536..7f3068c 100644
--- a/data/convert_patches_to_parquet.py
+++ b/data/convert_patches_to_parquet.py
@@ -10,7 +10,7 @@ SMALL_COMBINED_DIFF_THRESHOLD = 1000
 
 directory_of_script = pathlib.Path(__file__).parent.resolve()
 
-directory_of_tar_files = directory_of_script / "patches"
+directory_of_tar_files = directory_of_script / "patches.backup"
 all_diffs_output_path = directory_of_script / "all_diffs.parquet"
 small_diffs_output_path = directory_of_script / f"combined-diffs-less-than-{SMALL_COMBINED_DIFF_THRESHOLD}-chars.parquet"
 
diff --git a/train.py b/train.py
index ccabb69..e581f23 100644
--- a/train.py
+++ b/train.py
@@ -13,7 +13,7 @@ from data.dataset import load_huggingface_dataset
 
 
 MODEL_NAME = "meta-llama/Llama-3.2-1B"
-MAX_TOKEN_LENGTH = 1536
+MAX_TOKEN_LENGTH = 2048
 PARQUET_DATASET_PATH = Path("data/combined-diffs-less-than-1000-chars.parquet")
 
 

-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
################################################################################
diff --git a/train.py b/train.py
index e581f23..ccabb69 100644
--- a/train.py
+++ b/train.py
@@ -13,7 +13,7 @@ from data.dataset import load_huggingface_dataset
 
 
 MODEL_NAME = "meta-llama/Llama-3.2-1B"
-MAX_TOKEN_LENGTH = 2048
+MAX_TOKEN_LENGTH = 1536
 PARQUET_DATASET_PATH = Path("data/combined-diffs-less-than-1000-chars.parquet")
 
 
 ################################################################################
 ################################################################################
 
 directory_of_script = pathlib.Path(__file__).parent.resolve()
 
-directory_of_tar_files = directory_of_script / "patches"
+directory_of_tar_files = directory_of_script / "patches.backup"
 all_diffs_output_path = directory_of_script / "all_diffs.parquet"
 small_diffs_output_path = directory_of_script / f"combined-diffs-less-than-{SMALL_COMBINED_DIFF_THRESHOLD}-chars.parquet"
 
################################################################################
diff --git a/data/convert_patches_to_parquet.py b/data/convert_patches_to_parquet.py
index 19af536..7f3068c 100644
--- a/data/convert_patches_to_parquet.py
+++ b/data/convert_patches_to_parquet.py
@@ -10,7 +10,7 @@ SMALL_COMBINED_DIFF_THRESHOLD = 1000
 
 directory_of_script = pathlib.Path(__file__).parent.resolve()
 
-directory_of_tar_files = directory_of_script / "patches"
+directory_of_tar_files = directory_of_script / "patches.backup"
 all_diffs_output_path = directory_of_script / "all_diffs.parquet"
 small_diffs_output_path = directory_of_script / f"combined-diffs-less-than-{SMALL_COMBINED_DIFF_THRESHOLD}-chars.parquet"
 
diff --git a/train.py b/train.py
index ccabb69..e581f23 100644
--- a/train.py
+++ b/train.py
@@ -13,7 +13,7 @@ from data.dataset import load_huggingface_dataset
 
 
 MODEL_NAME = "meta-llama/Llama-3.2-1B"
-MAX_TOKEN_LENGTH = 1536
+MAX_TOKEN_LENGTH = 2048
 PARQUET_DATASET_PATH = Path("data/combined-diffs-less-than-1000-chars.parquet")
 
 

-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
################################################################################
diff --git a/train.py b/train.py
index e581f23..ccabb69 100644
--- a/train.py
+++ b/train.py
@@ -13,7 +13,7 @@ from data.dataset import load_huggingface_dataset
 
 
 MODEL_NAME = "meta-llama/Llama-3.2-1B"
-MAX_TOKEN_LENGTH = 2048
+MAX_TOKEN_LENGTH = 1536
 PARQUET_DATASET_PATH = Path("data/combined-diffs-less-than-1000-chars.parquet")
 
 
 ################################################################################
 ################################################################################
 
 directory_of_script = pathlib.Path(__file__).parent.resolve()
 
-directory_of_tar_files = directory_of_script / "patches"
+directory_of_tar_files = directory_of_script / "patches.backup"
 all_diffs_output_path = directory_of_script / "all_diffs.parquet"
 small_diffs_output_path = directory_of_script / f"combined-diffs-less-than-{SMALL_COMBINED_DIFF_THRESHOLD}-chars.parquet"
 
################################################################################
diff --git a/data/convert_patches_to_parquet.py b/data/convert_patches_to_parquet.py
index 19af536..7f3068c 100644
--- a/data/convert_patches_to_parquet.py
+++ b/data/convert_patches_to_parquet.py
@@ -10,7 +10,7 @@ SMALL_COMBINED_DIFF_THRESHOLD = 1000
 
 directory_of_script = pathlib.Path(__file__).parent.resolve()
 
-directory_of_tar_files = directory_of_script / "patches"
+directory_of_tar_files = directory_of_script / "patches.backup"
 all_diffs_output_path = directory_of_script / "all_diffs.parquet"
 small_diffs_output_path = directory_of_script / f"combined-diffs-less-than-{SMALL_COMBINED_DIFF_THRESHOLD}-chars.parquet"
 
diff --git a/train.py b/train.py
index ccabb69..e581f23 100644
--- a/train.py
+++ b/train.py
@@ -13,7 +13,7 @@ from data.dataset import load_huggingface_dataset
 
 
 MODEL_NAME = "meta-llama/Llama-3.2-1B"
-MAX_TOKEN_LENGTH = 1536
+MAX_TOKEN_LENGTH = 2048
 PARQUET_DATASET_PATH = Path("data/combined-diffs-less-than-1000-chars.parquet")
 
 



* saving patches
** save_patches.sh speed
50-55 minutes to save all 20 repos without optimization

*** 22.5 minutes just to run this on grpc (unoptimized version)
    for commit in $(git -C $full_repo_path rev-list HEAD); do
        if ! git -C $full_repo_path show --pretty=%p --quiet $commit | grep -q '^..........$'; then
            continue
        fi
        if ! git -C $full_repo_path show --pretty=%p --quiet "$commit^" | grep -q '^..........$'; then
            continue
        fi
        echo $commit
    done

optimized version: (3 lines) 13m49.907s


** TODO make save_patches run `git diff` only once for each commit pair

** TODO skip patches across 2 commits that are just 1 line?
Example: python-certifi-9e837a5fbd135b95057abb8f14b775a50aee8a01.multipatch 
same line was updated from 4.0 -> 4.1, then 4.1 to 4.2 by two separate commits, each touching only that line.

** last repos to finish saving patches for are
grpc (very last)
numpy (next last)
botocore
setuptools


* eval.py
for dataset of size 128:
batch size 32: 84.6 seconds
batch size 64: 57.5 seconds
batch size 128: 111.8 seconds

for dataset of size 256:
batch size of 256: 44 seconds
